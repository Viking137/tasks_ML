{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first project of a neural network, whose purpose is to classify images. We use the CIFAR10 dataset. Now install all the necessary packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import random\n",
    "from tqdm import *\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets\n",
    "import torchvision.transforms as transforms\n",
    "#%pip install -q torchinfo\n",
    "from torchinfo import summary\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fix the seed  \n",
    "\n",
    "def seed_everything(seed):\n",
    "    random.seed(seed) # fix the generate of random number\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed) # fix filling in hashes \n",
    "    np.random.seed(seed) # fix the generate of random number numpy\n",
    "    torch.manual_seed(seed) # fix the generate of random number pytorch\n",
    "    torch.cuda.manual_seed(seed) # fix the generate of random number for GPU\n",
    "    torch.backends.cudnn.deterministic = True # choose only deterministic algoritms (for conv)\n",
    "    torch.backends.cudnn.benchmark = False # fix algoritm estimation conv "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#class for experiment\n",
    "\n",
    "class CFG:\n",
    "\n",
    "  num_epochs = 10  \n",
    "  train_batch_size = 32  \n",
    "  test_batch_size = 512  \n",
    "  num_workers = 4  # num of process for simultaneous processing data (not critical parametr to small datasets)\n",
    "  lr = 3e-4 \n",
    "  seed = 42  \n",
    "  classes = ('airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def class2dict(class_data):\n",
    "  return dict((name, getattr(class_data, name)) for name in dir(class_data) if not name.startswith('__'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We implement the LeNet5 architecture. \n",
    "\n",
    "This type of architecture contains 8 levels, including output. It can be briefly described as follows: input -> convolutional layer with 6 feature maps -> pooling layer -> convolutional layer with 16 feature maps -> pooling layer -> then three fully connected layers -> output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LeNet5(torch.nn.Module):\n",
    "    def __init__(self,\n",
    "                 activation='tanh',\n",
    "                 pooling='avg',\n",
    "                 conv_size=5\n",
    "                ):\n",
    "        super(LeNet5, self).__init__()\n",
    "\n",
    "        self.conv_size = conv_size  # the size of the convolution window\n",
    "\n",
    "        #set the activation function to select\n",
    "        if activation == 'tanh':\n",
    "            activation_function = torch.nn.Tanh()\n",
    "        elif activation == 'relu':\n",
    "            activation_function = torch.nn.ReLU()\n",
    "        else:\n",
    "            raise NotImplementedError\n",
    "\n",
    "        # set the pooling type to select\n",
    "        if pooling == 'avg':\n",
    "            pooling_layer = torch.nn.AvgPool2d(kernel_size=2, stride=2)\n",
    "        elif pooling == 'max':\n",
    "            pooling_layer = torch.nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        else:\n",
    "            raise NotImplementedError\n",
    "\n",
    "        # set the core size of the first layer\n",
    "        if conv_size == 5:\n",
    "            self.conv1 = torch.nn.Conv2d(in_channels=1,\n",
    "                                         out_channels=6,\n",
    "                                         kernel_size=5,\n",
    "                                         padding=2)\n",
    "        elif conv_size == 3:\n",
    "            self.conv1_1 = torch.nn.Conv2d(in_channels=1,\n",
    "                                         out_channels=6,\n",
    "                                         kernel_size=3,\n",
    "                                         padding=1)\n",
    "            self.conv1_2 = torch.nn.Conv2d(in_channels=6,\n",
    "                                         out_channels=6,\n",
    "                                         kernel_size=3,\n",
    "                                         padding=1)\n",
    "        else:\n",
    "            raise NotImplementedError\n",
    "\n",
    "        self.act1 = activation_function\n",
    "        self.pool1 = pooling_layer\n",
    "\n",
    "        # set the core size of the second layer\n",
    "        if conv_size == 5:\n",
    "            self.conv2 = self.conv2 = torch.nn.Conv2d(in_channels=6,\n",
    "                                         out_channels=16,\n",
    "                                         kernel_size=5,\n",
    "                                         padding=0)\n",
    "        elif conv_size == 3:\n",
    "            self.conv2_1 = torch.nn.Conv2d(in_channels=6,\n",
    "                                         out_channels=16,\n",
    "                                         kernel_size=3,\n",
    "                                         padding=0)\n",
    "            self.conv2_2 = torch.nn.Conv2d(in_channels=16,\n",
    "                                         out_channels=16,\n",
    "                                         kernel_size=3,\n",
    "                                         padding=0)\n",
    "        else:\n",
    "            raise NotImplementedError\n",
    "\n",
    "        self.act2 = activation_function\n",
    "        self.pool2 = pooling_layer\n",
    "\n",
    "        # fully conected layer\n",
    "        self.fc1 = torch.nn.Linear(5 * 5 * 16, 120)\n",
    "        self.act3 = activation_function\n",
    "\n",
    "        self.fc2 = torch.nn.Linear(120, 84)\n",
    "        self.act4 = activation_function\n",
    "\n",
    "        self.fc3 = torch.nn.Linear(84, 10)\n",
    "\n",
    "    # forward propagation\n",
    "    def forward(self, x):\n",
    "        # first layer\n",
    "        if self.conv_size == 5:\n",
    "            x = self.conv1(x)\n",
    "        elif self.conv_size == 3:\n",
    "            x = self.conv1_2(self.conv1_1(x))\n",
    "\n",
    "        x = self.act1(x)\n",
    "        x = self.pool1(x)\n",
    "\n",
    "        # second layer\n",
    "        if self.conv_size == 5:\n",
    "            x = self.conv2(x)\n",
    "        elif self.conv_size == 3:\n",
    "            x = self.conv2_2(self.conv2_1(x))\n",
    "\n",
    "        x = self.act2(x)\n",
    "        x = self.pool2(x)\n",
    "\n",
    "        # fully conected layers\n",
    "        x = x.view(x.size(0), x.size(1) * x.size(2) * x.size(3))\n",
    "        x = self.fc1(x)\n",
    "        x = self.act3(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.act4(x)\n",
    "        x = self.fc3(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implementation of the function for training and testing the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, device, train_loader, optimizer, criterion, epoch):\n",
    "    model.train() # putting the model into training mode\n",
    "    train_loss = 0  \n",
    "    correct = 0  # initialize the proportion of correct predictions of the model\n",
    "\n",
    "    n_ex = len(train_loader)  # nums butch in train dataset \n",
    "\n",
    "    for batch_idx, (data, target) in tqdm(enumerate(train_loader), total=n_ex):\n",
    "        data, target = data.to(device), target.to(device)  \n",
    "        optimizer.zero_grad() \n",
    "        output = model(data)  # prediction of the model \n",
    "        pred = output.argmax(dim=1, keepdim=True)  # classes that the model predicted\n",
    "        correct += pred.eq(target.view_as(pred)).sum().item()  # count the proportion of correct predictions of the model\n",
    "        train_loss = criterion(output, target)  \n",
    "        train_loss.backward() \n",
    "        optimizer.step() # updating the weights of the model\n",
    "\n",
    "    tqdm.write('\\nTrain set: Average loss: {:.4f}, Accuracy: {:.2f}%'.format(\n",
    "        train_loss, 100. * correct / len(train_loader.dataset)))   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, device, test_loader, criterion):\n",
    "    model.eval() # putting the model into testing mode\n",
    "    train_loss = 0 \n",
    "    correct = 0  \n",
    "\n",
    "    with torch.no_grad(): # gradients are not counted in testing mode\n",
    "        for data, target in test_loader:\n",
    "            data, target = data.to(device), target.to(device)  \n",
    "            output = model(data)  \n",
    "            test_loss = criterion(output, target)  \n",
    "            pred = output.argmax(dim=1, keepdim=True)  \n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()  \n",
    "\n",
    "    tqdm.write('Test set: Average loss: {:.4f}, Accuracy: {:.2f}%'.format(\n",
    "        test_loss, 100. * correct / len(test_loader.dataset)))   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main_CIFAR(model):\n",
    "\n",
    "    use_cuda = torch.cuda.is_available()\n",
    "\n",
    "    seed_everything(CFG.seed)\n",
    "\n",
    "    device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "\n",
    "    kwargs = {'num_workers': CFG.num_workers, 'pin_memory': True} if use_cuda else {}\n",
    "\n",
    "    # download dataset CIFAR10\n",
    "    train_loader = torch.utils.data.DataLoader(\n",
    "        datasets.CIFAR10('../data', train=True, download=True,\n",
    "                       transform=transforms.Compose([\n",
    "                           transforms.ToTensor(),\n",
    "                           transforms.Normalize((0.4914, 0.4822, 0.4465), (0.247, 0.243, 0.261)) # normalizing the meaning\n",
    "                       ])),\n",
    "        batch_size=CFG.train_batch_size, shuffle=True, **kwargs)\n",
    "\n",
    "    test_loader = torch.utils.data.DataLoader(\n",
    "        datasets.CIFAR10('../data', train=False, transform=transforms.Compose([\n",
    "                           transforms.ToTensor(),\n",
    "                           transforms.Normalize((0.4914, 0.4822, 0.4465), (0.247, 0.243, 0.261))\n",
    "                       ])),\n",
    "        batch_size=CFG.test_batch_size, shuffle=False, **kwargs)\n",
    "\n",
    "    model = model.to(device)\n",
    "\n",
    "\n",
    "    optimizer = optim.Adam(model.parameters(),\n",
    "                          lr=CFG.lr)\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    for epoch in range(1, CFG.num_epochs + 1):\n",
    "        print('\\nEpoch:', epoch)\n",
    "        train(model, device, train_loader, optimizer, criterion, epoch)\n",
    "        test(model, device, test_loader, criterion)\n",
    "    print('Training is end!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a convolutional network \n",
    "class CIFAR_Net(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CIFAR_Net, self).__init__()\n",
    "\n",
    "        self.conv1 = torch.nn.Conv2d(3, 16, 3, padding=1)\n",
    "        self.act1  = torch.nn.ReLU()\n",
    "        self.pool1 = torch.nn.MaxPool2d(2, 2)\n",
    "\n",
    "        self.conv2 = torch.nn.Conv2d(16, 32, 3, padding=1)\n",
    "        self.act2  = torch.nn.ReLU()\n",
    "        self.pool2 = torch.nn.MaxPool2d(2, 2)\n",
    "\n",
    "        self.conv3 = torch.nn.Conv2d(32, 64, 3, padding=1)\n",
    "        self.act3  = torch.nn.ReLU()\n",
    "\n",
    "        self.fc1   = torch.nn.Linear(8 * 8 * 64, 256)\n",
    "        self.act4  = torch.nn.Tanh()\n",
    "\n",
    "        self.fc2   = torch.nn.Linear(256, 64)\n",
    "        self.act5  = torch.nn.Tanh()\n",
    "\n",
    "        self.fc3   = torch.nn.Linear(64, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.act1(x)\n",
    "        x = self.pool1(x)\n",
    "\n",
    "        x = self.conv2(x)\n",
    "        x = self.act2(x)\n",
    "        x = self.pool2(x)\n",
    "\n",
    "        x = self.conv3(x)\n",
    "        x = self.act3(x)\n",
    "\n",
    "        x = x.view(x.size(0), x.size(1) * x.size(2) * x.size(3))\n",
    "        x = self.fc1(x)\n",
    "        x = self.act4(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.act5(x)\n",
    "        x = self.fc3(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_CNN = CIFAR_Net()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "====================================================================================================\n",
       "Layer (type:depth-idx)                   Input Shape          Output Shape         Param #\n",
       "====================================================================================================\n",
       "CIFAR_Net                                [32, 3, 32, 32]      [32, 10]             --\n",
       "├─Conv2d: 1-1                            [32, 3, 32, 32]      [32, 16, 32, 32]     448\n",
       "├─ReLU: 1-2                              [32, 16, 32, 32]     [32, 16, 32, 32]     --\n",
       "├─MaxPool2d: 1-3                         [32, 16, 32, 32]     [32, 16, 16, 16]     --\n",
       "├─Conv2d: 1-4                            [32, 16, 16, 16]     [32, 32, 16, 16]     4,640\n",
       "├─ReLU: 1-5                              [32, 32, 16, 16]     [32, 32, 16, 16]     --\n",
       "├─MaxPool2d: 1-6                         [32, 32, 16, 16]     [32, 32, 8, 8]       --\n",
       "├─Conv2d: 1-7                            [32, 32, 8, 8]       [32, 64, 8, 8]       18,496\n",
       "├─ReLU: 1-8                              [32, 64, 8, 8]       [32, 64, 8, 8]       --\n",
       "├─Linear: 1-9                            [32, 4096]           [32, 256]            1,048,832\n",
       "├─Tanh: 1-10                             [32, 256]            [32, 256]            --\n",
       "├─Linear: 1-11                           [32, 256]            [32, 64]             16,448\n",
       "├─Tanh: 1-12                             [32, 64]             [32, 64]             --\n",
       "├─Linear: 1-13                           [32, 64]             [32, 10]             650\n",
       "====================================================================================================\n",
       "Total params: 1,089,514\n",
       "Trainable params: 1,089,514\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (M): 124.68\n",
       "====================================================================================================\n",
       "Input size (MB): 0.39\n",
       "Forward/backward pass size (MB): 7.42\n",
       "Params size (MB): 4.36\n",
       "Estimated Total Size (MB): 12.18\n",
       "===================================================================================================="
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary(model=model_CNN,\n",
    "        input_size=(32, 3, 32, 32), # input batch\n",
    "        col_names=[\"input_size\", \"output_size\", \"num_params\"], # what want to see\n",
    "        col_width=20\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "\n",
      "Epoch: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1563/1563 [01:33<00:00, 16.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train set: Average loss: 1.4950, Accuracy: 48.81%\n",
      "Test set: Average loss: 1.2161, Accuracy: 59.33%\n",
      "\n",
      "Epoch: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1563/1563 [01:33<00:00, 16.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train set: Average loss: 1.1561, Accuracy: 63.10%\n",
      "Test set: Average loss: 1.1204, Accuracy: 64.10%\n",
      "\n",
      "Epoch: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1563/1563 [01:32<00:00, 16.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train set: Average loss: 0.7673, Accuracy: 69.16%\n",
      "Test set: Average loss: 1.0160, Accuracy: 67.78%\n",
      "\n",
      "Epoch: 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1563/1563 [01:29<00:00, 17.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train set: Average loss: 0.7138, Accuracy: 73.12%\n",
      "Test set: Average loss: 0.9874, Accuracy: 69.43%\n",
      "\n",
      "Epoch: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1563/1563 [01:29<00:00, 17.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train set: Average loss: 0.8714, Accuracy: 76.48%\n",
      "Test set: Average loss: 1.0616, Accuracy: 69.61%\n",
      "\n",
      "Epoch: 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1563/1563 [01:30<00:00, 17.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train set: Average loss: 0.4142, Accuracy: 79.85%\n",
      "Test set: Average loss: 0.9528, Accuracy: 71.85%\n",
      "\n",
      "Epoch: 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1563/1563 [01:29<00:00, 17.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train set: Average loss: 0.3773, Accuracy: 83.14%\n",
      "Test set: Average loss: 0.9431, Accuracy: 71.55%\n",
      "\n",
      "Epoch: 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1563/1563 [01:29<00:00, 17.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train set: Average loss: 0.4931, Accuracy: 86.55%\n",
      "Test set: Average loss: 1.0296, Accuracy: 72.09%\n",
      "\n",
      "Epoch: 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1563/1563 [01:29<00:00, 17.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train set: Average loss: 0.3742, Accuracy: 89.82%\n",
      "Test set: Average loss: 1.0832, Accuracy: 72.16%\n",
      "\n",
      "Epoch: 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1563/1563 [01:29<00:00, 17.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train set: Average loss: 0.1419, Accuracy: 92.78%\n",
      "Test set: Average loss: 1.0921, Accuracy: 72.10%\n",
      "Training is end!\n"
     ]
    }
   ],
   "source": [
    "main_CIFAR(model_CNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_check(model, device):\n",
    "    model.eval() \n",
    "    for i in range(1, 11):\n",
    "        data = Image.open(f\"img{i}.jpg\") \n",
    "        data = data.resize((32,32),Image.ANTIALIAS)\n",
    "        transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.4914, 0.4822, 0.4465), (0.247, 0.243, 0.261))])\n",
    "        data_transf = transform(data)\n",
    "\n",
    "        classes = ('airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
    "        \n",
    "        data_transf.unsqueeze_(0)\n",
    "        with torch.no_grad(): \n",
    "            data_transf = data_transf.to(device)\n",
    "            output = model(data_transf)\n",
    "            pred = output.argmax(dim=1, keepdim=True)\n",
    "            print(classes[pred.item()])    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bird\n",
      "airplane\n",
      "automobile\n",
      "dog\n",
      "deer\n",
      "dog\n",
      "airplane\n",
      "horse\n",
      "ship\n",
      "truck\n"
     ]
    }
   ],
   "source": [
    "use_cuda = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "test_check(model_CNN, device)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.5 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c6aeca87e53583627b8b79e4f4da41d10e1acf8a2564923b7f23db1af83b45f2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
