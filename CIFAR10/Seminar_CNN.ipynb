{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3di7IOVmTsYb"
      },
      "source": [
        "# Свертка"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-02-22T17:31:00.391071Z",
          "start_time": "2023-02-22T17:31:00.005862Z"
        },
        "id": "ZiQNcwpVUJrb"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import imageio\n",
        "import cv2\n",
        "\n",
        "from matplotlib import pyplot as plt\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZPM_9lqBYrCV"
      },
      "source": [
        "# Сверточная нейронная сеть"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zqdVrc5FaG6O"
      },
      "source": [
        "***Свёрточная нейросеть (Convolutional Neural Network, CNN)*** - это многослойная нейросеть, имеющая в своей архитектуре помимо полносвязных слоёв (а иногда их может и не быть) ещё и **свёрточные слои (Conv Layers)** и **pooling-слои (Pool Layers)**.  \n",
        "\n",
        "Вот так выглядит неглубокая свёрточная нейросеть, имеющая такую архитектуру:  \n",
        "`Input -> Conv 5x5 -> Pool 2x2 -> Conv 5x5 -> Pool 2x2 -> FC -> Output`\n",
        "\n",
        "<img src=\"https://camo.githubusercontent.com/269e3903f62eb2c4d13ac4c9ab979510010f8968/68747470733a2f2f7261772e6769746875622e636f6d2f746176677265656e2f6c616e647573655f636c617373696669636174696f6e2f6d61737465722f66696c652f636e6e2e706e673f7261773d74727565\" width=800>\n",
        "\n",
        "Свёрточные нейросети почти всегда строятся по следующему правилу:  \n",
        "\n",
        "`INPUT -> [[CONV -> RELU]*N -> POOL]*M -> [FC -> RELU]*K -> FC`  \n",
        "\n",
        "\n",
        "1) ***Входной слой*** (batch картинок `HxWxC`)  \n",
        "\n",
        "2) $M$ блоков из $N$ свёрток и pooling-ов, причём именно в том порядке, как в формуле выше. Все эти $M$ блоков вместе называют ***feature extractor*** свёрточной нейросети, потому что эта часть сети отвечает непосредственно за формирование новых, более сложных признаков, поверх тех, которые подаются.   \n",
        "\n",
        "3) $K$ штук Fully-Connected-слоёв (с активациями). Эту часть из $K$ FC-слоёв называют ***classificator***, поскольку эти слои отвечают непосредственно за предсказание нужного класса."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w2Wwtk4_baUE"
      },
      "source": [
        "Ещё раз вспомним про основные компоненты нейросети:\n",
        "\n",
        "- сама **архитектура** нейросети (сюда входят типы функций активации у каждого нейрона);\n",
        "- начальная **инициализация** весов каждого слоя;\n",
        "- метод **оптимизации** нейросети (сюда ещё входит метод изменения `learning_rate`);\n",
        "- размер **батчей** (`batch_size`);\n",
        "- количетсво итераций обучения (`num_epochs`);\n",
        "- **функция потерь** (`loss`);  \n",
        "- тип **регуляризации** нейросети (для каждого слоя можно свой);  \n",
        "\n",
        "Так как мы сейчас рассматриваем **CNN**, то, помимо этих компонент, в свёрточной нейросети можно настроить следующие параметры:  \n",
        "\n",
        "- в каждом ConvLayer:\n",
        "  - **размер фильтров (окна свёртки)** (`kernel_size`)\n",
        "  - **количество фильтров** (`out_channels`)  \n",
        "  - **шага окна свёртки (stride)** (`stride`)  \n",
        "  - **тип padding'а** (`padding`)  \n",
        "\n",
        "\n",
        "- в каждом PoolLayer:\n",
        "  - **размер окна pooling'a** (`kernel_size`)  \n",
        "  - **шаг окна pooling'а** (`stride`)  \n",
        "  - **тип pooling'а** (`pool_type`)  \n",
        "  - **тип padding'а** (`padding`)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r399kcfkcToT"
      },
      "source": [
        "Посмотрим, как работает CNN на датасетах MNIST и CIFAR10."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wx-JDGrEcdPD"
      },
      "source": [
        "<img src=\"http://present5.com/presentation/20143288_415358496/image-8.jpg\" width=500>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jBU-pdnJcjAY"
      },
      "source": [
        "**MNIST:** это набор из 70k картинок рукописных цифр от 0 до 9, написанных людьми, 60k из которых являются тренировочной выборкой (`train` dataset)), и ещё 10k выделены для тестирования модели (`test` dataset)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LTKLkWWrcowv"
      },
      "source": [
        "<img src=\"https://raw.githubusercontent.com/soumith/ex/gh-pages/assets/cifar10.png\" width=500>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hT4oNHFScu8F"
      },
      "source": [
        "**CIFAR10:** это набор из 60k картинок 32х32х3, 50k которых составляют обучающую выборку, и оставшиеся 10k - тестовую. Классов в этом датасете 10: `'plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck'`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-02-22T18:01:39.023928Z",
          "start_time": "2023-02-22T18:01:39.005327Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KVJY3eZGc5zF",
        "outputId": "14ce0d34-92f9-47d4-d221-bc832cf0701c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[INFO] Couldn't find torchinfo... installing it.\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "import numpy as np\n",
        "import random\n",
        "from tqdm import *\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "try:\n",
        "    from torchinfo import summary\n",
        "except:\n",
        "    print(\"[INFO] Couldn't find torchinfo... installing it.\")\n",
        "    !pip install -q torchinfo\n",
        "    from torchinfo import summary\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-02-22T17:53:30.574321Z",
          "start_time": "2023-02-22T17:53:30.566454Z"
        },
        "id": "ga2wIcnkdLN-"
      },
      "outputs": [],
      "source": [
        "# Зафиксируем seed для воспроизводимости\n",
        "\n",
        "def seed_everything(seed):\n",
        "    random.seed(seed) # фиксируем генератор случайных чисел\n",
        "    os.environ['PYTHONHASHSEED'] = str(seed) # фиксируем заполнения хешей\n",
        "    np.random.seed(seed) # фиксируем генератор случайных чисел numpy\n",
        "    torch.manual_seed(seed) # фиксируем генератор случайных чисел pytorch\n",
        "    torch.cuda.manual_seed(seed) # фиксируем генератор случайных чисел для GPU\n",
        "    torch.backends.cudnn.deterministic = True # выбираем только детерминированные алгоритмы (для сверток)\n",
        "    torch.backends.cudnn.benchmark = False # фиксируем алгоритм вычисления сверток"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-02-22T17:54:47.752355Z",
          "start_time": "2023-02-22T17:54:47.736351Z"
        },
        "id": "lOPrtatydOmA"
      },
      "outputs": [],
      "source": [
        "class CFG:\n",
        "\n",
        "# Задаем параметры нашего эксперимента\n",
        "  num_epochs = 10  # число эпох\n",
        "  train_batch_size = 32  # размер батча для тренировки модели\n",
        "  test_batch_size = 512  # размер батча для тестирования модели\n",
        "  num_workers = 4  # число процессов для одновременной обработки данных (некритичный параметр при небольших датасетах)\n",
        "  lr = 3e-4  # learning rate\n",
        "  seed = 42  # random seed\n",
        "  classes = ('airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')  # классы из датасета CIFAR10\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-02-22T17:55:00.112118Z",
          "start_time": "2023-02-22T17:55:00.099096Z"
        },
        "id": "D6F6baEzdWua"
      },
      "outputs": [],
      "source": [
        "# Переведем наш класс с параметрами в словарь\n",
        "\n",
        "def class2dict(f):\n",
        "  return dict((name, getattr(f, name)) for name in dir(f) if not name.startswith('__'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yo9zgoUHdpSn"
      },
      "source": [
        "Построим нашу первую сверточную сеть LeNet5 (привет, Ян Лекун!)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-02-22T18:17:39.005093Z",
          "start_time": "2023-02-22T18:17:38.988090Z"
        },
        "id": "g6as6a5sdz7E"
      },
      "outputs": [],
      "source": [
        "class LeNet5(torch.nn.Module):\n",
        "    def __init__(self,\n",
        "                 activation='tanh',\n",
        "                 pooling='avg',\n",
        "                 conv_size=5\n",
        "                ):\n",
        "        super(LeNet5, self).__init__()\n",
        "\n",
        "        self.conv_size = conv_size  # размер окна свёртки\n",
        "\n",
        "        # установим на выбор функции активации\n",
        "        if activation == 'tanh':\n",
        "            activation_function = torch.nn.Tanh()\n",
        "        elif activation == 'relu':\n",
        "            activation_function = torch.nn.ReLU()\n",
        "        else:\n",
        "            raise NotImplementedError\n",
        "\n",
        "        # установим на выбор тип пулинга\n",
        "        if pooling == 'avg':\n",
        "            pooling_layer = torch.nn.AvgPool2d(kernel_size=2, stride=2)\n",
        "        elif pooling == 'max':\n",
        "            pooling_layer = torch.nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "        else:\n",
        "            raise NotImplementedError\n",
        "\n",
        "        # установим на выбор размер ядра 1 слоя\n",
        "        if conv_size == 5:\n",
        "            self.conv1 = torch.nn.Conv2d(in_channels=1,\n",
        "                                         out_channels=6,\n",
        "                                         kernel_size=5,\n",
        "                                         padding=2)\n",
        "        elif conv_size == 3:\n",
        "            self.conv1_1 = torch.nn.Conv2d(in_channels=1,\n",
        "                                         out_channels=6,\n",
        "                                         kernel_size=3,\n",
        "                                         padding=1)\n",
        "            self.conv1_2 = torch.nn.Conv2d(in_channels=6,\n",
        "                                         out_channels=6,\n",
        "                                         kernel_size=3,\n",
        "                                         padding=1)\n",
        "        else:\n",
        "            raise NotImplementedError\n",
        "\n",
        "        self.act1 = activation_function\n",
        "        self.pool1 = pooling_layer\n",
        "\n",
        "        # установим на выбор размер ядра 2 слоя\n",
        "        if conv_size == 5:\n",
        "            self.conv2 = self.conv2 = torch.nn.Conv2d(in_channels=6,\n",
        "                                         out_channels=16,\n",
        "                                         kernel_size=5,\n",
        "                                         padding=0)\n",
        "        elif conv_size == 3:\n",
        "            self.conv2_1 = torch.nn.Conv2d(in_channels=6,\n",
        "                                         out_channels=16,\n",
        "                                         kernel_size=3,\n",
        "                                         padding=0)\n",
        "            self.conv2_2 = torch.nn.Conv2d(in_channels=16,\n",
        "                                         out_channels=16,\n",
        "                                         kernel_size=3,\n",
        "                                         padding=0)\n",
        "        else:\n",
        "            raise NotImplementedError\n",
        "\n",
        "        self.act2 = activation_function\n",
        "        self.pool2 = pooling_layer\n",
        "\n",
        "        # не забываем про полносвязанные слои\n",
        "        self.fc1 = torch.nn.Linear(5 * 5 * 16, 120)\n",
        "        self.act3 = activation_function\n",
        "\n",
        "        self.fc2 = torch.nn.Linear(120, 84)\n",
        "        self.act4 = activation_function\n",
        "\n",
        "        self.fc3 = torch.nn.Linear(84, 10)\n",
        "\n",
        "    # прямой проход\n",
        "    def forward(self, x):\n",
        "        # 1ый слой сети\n",
        "        if self.conv_size == 5:\n",
        "            x = self.conv1(x)\n",
        "        elif self.conv_size == 3:\n",
        "            x = self.conv1_2(self.conv1_1(x))\n",
        "\n",
        "        x = self.act1(x)\n",
        "        x = self.pool1(x)\n",
        "\n",
        "        # 2ой слой сети\n",
        "        if self.conv_size == 5:\n",
        "            x = self.conv2(x)\n",
        "        elif self.conv_size == 3:\n",
        "            x = self.conv2_2(self.conv2_1(x))\n",
        "\n",
        "        x = self.act2(x)\n",
        "        x = self.pool2(x)\n",
        "\n",
        "        # полносвязные слои сети\n",
        "        x = x.view(x.size(0), x.size(1) * x.size(2) * x.size(3))\n",
        "        x = self.fc1(x)\n",
        "        x = self.act3(x)\n",
        "        x = self.fc2(x)\n",
        "        x = self.act4(x)\n",
        "        x = self.fc3(x)\n",
        "\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-02-22T18:22:16.924813Z",
          "start_time": "2023-02-22T18:22:16.910748Z"
        },
        "id": "2OBS68QddfFe"
      },
      "outputs": [],
      "source": [
        "# функция обучения\n",
        "def train(model, device, train_loader, optimizer, criterion, epoch):\n",
        "    model.train() # переводим модель в режим обучения\n",
        "    train_loss = 0  # инициализируем значение ошибки\n",
        "    correct = 0  # иницилиазируем долю верно предсказанных объектов\n",
        "\n",
        "    n_ex = len(train_loader)  # количество батчей в тренировочном датасете\n",
        "\n",
        "    for batch_idx, (data, target) in tqdm(enumerate(train_loader), total=n_ex):\n",
        "        data, target = data.to(device), target.to(device)  # отправляем данные на девайс (CPU или GPU), где находится модель\n",
        "\n",
        "        optimizer.zero_grad() # обнуляем градиенты\n",
        "\n",
        "        output = model(data)  # вызываем предсказание модели\n",
        "\n",
        "        pred = output.argmax(dim=1, keepdim=True)  # получаем классы, который предсказала для каждого объекта\n",
        "\n",
        "        correct += pred.eq(target.view_as(pred)).sum().item()  # считаем долю верно предсказанных объектов\n",
        "\n",
        "        train_loss = criterion(output, target)  # считаем значение функции ошибки\n",
        "        train_loss.backward() # обратное распространение функции ошибки (расчёт градиентов)\n",
        "        optimizer.step() # делаем шаг оптимизатором (обновляем веса модели)\n",
        "\n",
        "    tqdm.write('\\nTrain set: Average loss: {:.4f}, Accuracy: {:.2f}%'.format(\n",
        "        train_loss, 100. * correct / len(train_loader.dataset)))   # выводим результаты после одной эпохи"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-02-22T18:22:38.252188Z",
          "start_time": "2023-02-22T18:22:38.245905Z"
        },
        "code_folding": [
          5
        ],
        "id": "5vyMTC7Iej78"
      },
      "outputs": [],
      "source": [
        "# функция инференса\n",
        "def test(model, device, test_loader, criterion):\n",
        "    model.eval() # переводим модель в режим тестирования\n",
        "    train_loss = 0  # инициализируем значение ошибки\n",
        "    correct = 0  # иницилиазируем долю верно предсказанных объектов\n",
        "\n",
        "    with torch.no_grad(): # указываем, что не нужно считать градиенты, так как это режим тестирования\n",
        "        for data, target in test_loader:\n",
        "            data, target = data.to(device), target.to(device)  # отправляем данные на девайс (CPU или GPU)\n",
        "            output = model(data)  # вызываем предсказание модели\n",
        "            test_loss = criterion(output, target)  # считаем значение функции ошибки\n",
        "            pred = output.argmax(dim=1, keepdim=True)  # получаем классы, который предсказала для каждого объекта\n",
        "            correct += pred.eq(target.view_as(pred)).sum().item()  # считаем долю верно предсказанных объектов\n",
        "\n",
        "    tqdm.write('Test set: Average loss: {:.4f}, Accuracy: {:.2f}%'.format(\n",
        "        test_loss, 100. * correct / len(test_loader.dataset)))   # выводим результаты после одной эпохи"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-02-22T18:22:50.355817Z",
          "start_time": "2023-02-22T18:22:50.343727Z"
        },
        "id": "c8fqk-X4erMC"
      },
      "outputs": [],
      "source": [
        "def main_MNIST(model):\n",
        "\n",
        "    use_cuda = torch.cuda.is_available() # проверяем, доступна ли нам GPU\n",
        "\n",
        "    seed_everything(CFG.seed) # фиксируем random seed\n",
        "\n",
        "    device = torch.device(\"cuda\" if use_cuda else \"cpu\") # определяем, какой девайс нам доступен (GPU или CPU)\n",
        "\n",
        "    kwargs = {'num_workers': CFG.num_workers, 'pin_memory': True} if use_cuda else {}\n",
        "\n",
        "    # загружаем датасет MNIST\n",
        "    train_loader = torch.utils.data.DataLoader(\n",
        "        datasets.MNIST('../data', train=True, download=True,\n",
        "                       transform=transforms.Compose([\n",
        "                           transforms.ToTensor(),\n",
        "                           transforms.Normalize((0.1307,), (0.3081,)) # значения среднего и стандартного отклонения\n",
        "                       ])),\n",
        "        batch_size=CFG.train_batch_size, shuffle=True, **kwargs)\n",
        "\n",
        "    test_loader = torch.utils.data.DataLoader(\n",
        "        datasets.MNIST('../data', train=False, transform=transforms.Compose([\n",
        "                           transforms.ToTensor(),\n",
        "                           transforms.Normalize((0.1307,), (0.3081,))\n",
        "                       ])),\n",
        "        batch_size=CFG.test_batch_size, shuffle=False, **kwargs)\n",
        "\n",
        "    model = model.to(device) # отправляем модель на девайс (GPU, если доступна, иначе CPU), где находится модель\n",
        "\n",
        "\n",
        "    optimizer = optim.Adam(model.parameters(),\n",
        "                          lr=CFG.lr) # инициализируем оптимизатор и отправляем ему веса модели и значение learning rate\n",
        "\n",
        "    criterion = nn.CrossEntropyLoss() # инициализируем функцию ошибки\n",
        "\n",
        "    for epoch in range(1, CFG.num_epochs + 1): # начинаем цикл обучения и тестирования\n",
        "        print('\\nEpoch:', epoch)\n",
        "        train(model, device, train_loader, optimizer, criterion, epoch)  # обучение одной эпохи\n",
        "        test(model, device, test_loader, criterion)  # тестирование после обучения одной эпохи\n",
        "    print('Training is end!')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-02-22T18:22:55.005617Z",
          "start_time": "2023-02-22T18:22:54.997243Z"
        },
        "id": "K6hA4OdReyt9"
      },
      "outputs": [],
      "source": [
        "# будем сравнивать модели\n",
        "model_1 = LeNet5(activation='tanh', conv_size=5)\n",
        "model_2 = LeNet5(activation='relu', conv_size=5)\n",
        "model_3 = LeNet5(activation='relu', conv_size=3)\n",
        "model_4 = LeNet5(activation='relu', conv_size=3, pooling='max')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-02-22T18:22:58.425219Z",
          "start_time": "2023-02-22T18:22:58.410645Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gj6IgN1qe7k5",
        "outputId": "545c33ca-c736-43a4-ee1c-623663703042"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "====================================================================================================\n",
              "Layer (type:depth-idx)                   Input Shape          Output Shape         Param #\n",
              "====================================================================================================\n",
              "LeNet5                                   [32, 1, 28, 28]      [32, 10]             --\n",
              "├─Conv2d: 1-1                            [32, 1, 28, 28]      [32, 6, 28, 28]      60\n",
              "├─Conv2d: 1-2                            [32, 6, 28, 28]      [32, 6, 28, 28]      330\n",
              "├─ReLU: 1-3                              [32, 6, 28, 28]      [32, 6, 28, 28]      --\n",
              "├─MaxPool2d: 1-4                         [32, 6, 28, 28]      [32, 6, 14, 14]      --\n",
              "├─Conv2d: 1-5                            [32, 6, 14, 14]      [32, 16, 12, 12]     880\n",
              "├─Conv2d: 1-6                            [32, 16, 12, 12]     [32, 16, 10, 10]     2,320\n",
              "├─ReLU: 1-7                              [32, 16, 10, 10]     [32, 16, 10, 10]     --\n",
              "├─MaxPool2d: 1-8                         [32, 16, 10, 10]     [32, 16, 5, 5]       --\n",
              "├─Linear: 1-9                            [32, 400]            [32, 120]            48,120\n",
              "├─ReLU: 1-10                             [32, 120]            [32, 120]            --\n",
              "├─Linear: 1-11                           [32, 120]            [32, 84]             10,164\n",
              "├─ReLU: 1-12                             [32, 84]             [32, 84]             --\n",
              "├─Linear: 1-13                           [32, 84]             [32, 10]             850\n",
              "====================================================================================================\n",
              "Total params: 62,724\n",
              "Trainable params: 62,724\n",
              "Non-trainable params: 0\n",
              "Total mult-adds (M): 23.16\n",
              "====================================================================================================\n",
              "Input size (MB): 0.10\n",
              "Forward/backward pass size (MB): 3.46\n",
              "Params size (MB): 0.25\n",
              "Estimated Total Size (MB): 3.81\n",
              "===================================================================================================="
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Вывод информации о модели с помощью torchinfo\n",
        "summary(model=model_4,\n",
        "        input_size=(32, 1, 28, 28), # входной батч\n",
        "        col_names=[\"input_size\", \"output_size\", \"num_params\"], # что хотим посмотреть\n",
        "        col_width=20\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-02-22T18:30:30.629576Z",
          "start_time": "2023-02-22T18:23:02.970940Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "BXu6S05Zfog7",
        "outputId": "0c9c2778-e750-4f09-938f-85080e2b1257",
        "scrolled": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to ../data/MNIST/raw/train-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 9912422/9912422 [00:00<00:00, 39635362.09it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracting ../data/MNIST/raw/train-images-idx3-ubyte.gz to ../data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to ../data/MNIST/raw/train-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 28881/28881 [00:00<00:00, 111440380.70it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracting ../data/MNIST/raw/train-labels-idx1-ubyte.gz to ../data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to ../data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1648877/1648877 [00:00<00:00, 43487146.67it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracting ../data/MNIST/raw/t10k-images-idx3-ubyte.gz to ../data/MNIST/raw\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to ../data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 4542/4542 [00:00<00:00, 10068989.84it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracting ../data/MNIST/raw/t10k-labels-idx1-ubyte.gz to ../data/MNIST/raw\n",
            "\n",
            "\n",
            "Epoch: 1\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "100%|██████████| 1875/1875 [00:20<00:00, 91.04it/s] "
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Train set: Average loss: 0.1022, Accuracy: 91.94%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test set: Average loss: 0.1918, Accuracy: 97.02%\n",
            "\n",
            "Epoch: 2\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 51%|█████     | 957/1875 [00:10<00:08, 104.16it/s]Exception in thread Thread-13 (_pin_memory_loop):\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/threading.py\", line 1016, in _bootstrap_inner\n",
            " 51%|█████     | 960/1875 [00:10<00:10, 90.60it/s] \n",
            "    self.run()\n",
            "  File \"/usr/lib/python3.10/threading.py\", line 953, in run\n",
            "    self._target(*self._args, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/pin_memory.py\", line 54, in _pin_memory_loop\n",
            "    do_one_step()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/pin_memory.py\", line 31, in do_one_step\n",
            "    r = in_queue.get(timeout=MP_STATUS_CHECK_INTERVAL)\n",
            "  File \"/usr/lib/python3.10/multiprocessing/queues.py\", line 122, in get\n",
            "    return _ForkingPickler.loads(res)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/multiprocessing/reductions.py\", line 355, in rebuild_storage_fd\n",
            "    fd = df.detach()\n",
            "  File \"/usr/lib/python3.10/multiprocessing/resource_sharer.py\", line 57, in detach\n",
            "    with _resource_sharer.get_connection(self._id) as conn:\n",
            "  File \"/usr/lib/python3.10/multiprocessing/resource_sharer.py\", line 86, in get_connection\n",
            "    c = Client(address, authkey=process.current_process().authkey)\n",
            "  File \"/usr/lib/python3.10/multiprocessing/connection.py\", line 502, in Client\n",
            "    c = SocketClient(address)\n",
            "  File \"/usr/lib/python3.10/multiprocessing/connection.py\", line 630, in SocketClient\n",
            "    s.connect(address)\n",
            "FileNotFoundError: [Errno 2] No such file or directory\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-14-c3e94c43db62>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmain_MNIST\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-13-6f57ee439436>\u001b[0m in \u001b[0;36mmain_MNIST\u001b[0;34m(model)\u001b[0m\n\u001b[1;32m     35\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCFG\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_epochs\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'\\nEpoch:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m         \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m         \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Training is end!'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-7-423d0f72bbaa>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, device, train_loader, optimizer, criterion, epoch)\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# обнуляем градиенты\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1517\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1518\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1519\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1520\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1525\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1526\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1528\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1529\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-6-89b73a002703>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     99\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mact4\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 101\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1517\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1518\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1519\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1520\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1525\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1526\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1528\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1529\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "# запускаем цикл обучения и тестирования\n",
        "main_MNIST(model_4)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ACXgiJsonHoT"
      },
      "source": [
        "Давайте теперь устроим небольшой поединок между полносвязанной сетью и сверточной на датасете CIFAR10."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-02-22T18:30:30.644866Z",
          "start_time": "2023-02-22T18:30:30.632221Z"
        },
        "id": "hYSS0x07iN8a"
      },
      "outputs": [],
      "source": [
        "def main_CIFAR(model):\n",
        "\n",
        "    use_cuda = torch.cuda.is_available()\n",
        "\n",
        "    seed_everything(CFG.seed)\n",
        "\n",
        "    device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
        "\n",
        "    kwargs = {'num_workers': CFG.num_workers, 'pin_memory': True} if use_cuda else {}\n",
        "\n",
        "    # загружаем датасет CIFAR10\n",
        "    train_loader = torch.utils.data.DataLoader(\n",
        "        datasets.CIFAR10('../data', train=True, download=True,\n",
        "                       transform=transforms.Compose([\n",
        "                           transforms.ToTensor(),\n",
        "                           transforms.Normalize((0.4914, 0.4822, 0.4465), (0.247, 0.243, 0.261)) # нормализуем значения\n",
        "                       ])),\n",
        "        batch_size=CFG.train_batch_size, shuffle=True, **kwargs)\n",
        "\n",
        "    test_loader = torch.utils.data.DataLoader(\n",
        "        datasets.CIFAR10('../data', train=False, transform=transforms.Compose([\n",
        "                           transforms.ToTensor(),\n",
        "                           transforms.Normalize((0.4914, 0.4822, 0.4465), (0.247, 0.243, 0.261))\n",
        "                       ])),\n",
        "        batch_size=CFG.test_batch_size, shuffle=False, **kwargs)\n",
        "\n",
        "    model = model.to(device)\n",
        "\n",
        "\n",
        "    optimizer = optim.Adam(model.parameters(),\n",
        "                          lr=CFG.lr)\n",
        "\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "    for epoch in range(1, CFG.num_epochs + 1):\n",
        "        print('\\nEpoch:', epoch)\n",
        "        train(model, device, train_loader, optimizer, criterion, epoch)\n",
        "        test(model, device, test_loader, criterion)\n",
        "    print('Training is end!')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-02-22T18:35:51.992015Z",
          "start_time": "2023-02-22T18:35:51.970970Z"
        },
        "id": "hXAFzKiSggjf"
      },
      "outputs": [],
      "source": [
        "# определяем полносвязанную сеть\n",
        "class FC_Net(nn.Module):\n",
        "    def __init__(self, constant_weight=None, normal=False,\n",
        "                 xavier_uniform=False, he_normal=False):\n",
        "        super(FC_Net, self).__init__()\n",
        "\n",
        "        self.fc1 = nn.Linear(3072, 1024)\n",
        "        self.fc2 = nn.Linear(1024, 512)\n",
        "        self.fc3 = nn.Linear(512, 128)\n",
        "        self.fc4 = nn.Linear(128, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.view(-1, 3072)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = F.relu(self.fc3(x))\n",
        "        x = self.fc4(x)\n",
        "\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-02-22T18:36:19.207871Z",
          "start_time": "2023-02-22T18:36:19.001476Z"
        },
        "id": "91Bc0Rgth29r"
      },
      "outputs": [],
      "source": [
        "model_1 = FC_Net()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-02-22T18:51:33.290805Z",
          "start_time": "2023-02-22T18:36:21.489986Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lj81GkUniCVi",
        "outputId": "436c3be6-976f-48b5-da78-e4072a1070d9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ../data/cifar-10-python.tar.gz\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 170498071/170498071 [00:05<00:00, 30130689.97it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracting ../data/cifar-10-python.tar.gz to ../data\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch: 1\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1563/1563 [00:16<00:00, 94.29it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Train set: Average loss: 1.4803, Accuracy: 41.95%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test set: Average loss: 1.5240, Accuracy: 47.65%\n",
            "\n",
            "Epoch: 2\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1563/1563 [00:16<00:00, 94.01it/s] "
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Train set: Average loss: 1.1858, Accuracy: 50.18%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test set: Average loss: 1.4576, Accuracy: 50.68%\n",
            "\n",
            "Epoch: 3\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1563/1563 [00:17<00:00, 89.45it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Train set: Average loss: 1.3078, Accuracy: 54.46%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test set: Average loss: 1.4662, Accuracy: 50.98%\n",
            "\n",
            "Epoch: 4\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1563/1563 [00:19<00:00, 79.47it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Train set: Average loss: 1.0130, Accuracy: 58.42%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test set: Average loss: 1.4583, Accuracy: 53.24%\n",
            "\n",
            "Epoch: 5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1563/1563 [00:21<00:00, 73.05it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Train set: Average loss: 1.5947, Accuracy: 62.01%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test set: Average loss: 1.4953, Accuracy: 54.74%\n",
            "\n",
            "Epoch: 6\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1563/1563 [00:18<00:00, 84.92it/s] "
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Train set: Average loss: 1.0262, Accuracy: 65.43%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test set: Average loss: 1.5244, Accuracy: 54.70%\n",
            "\n",
            "Epoch: 7\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1563/1563 [00:20<00:00, 76.52it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Train set: Average loss: 0.8670, Accuracy: 68.90%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test set: Average loss: 1.4348, Accuracy: 54.55%\n",
            "\n",
            "Epoch: 8\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1563/1563 [00:18<00:00, 85.40it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Train set: Average loss: 0.5632, Accuracy: 72.19%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test set: Average loss: 1.5996, Accuracy: 54.37%\n",
            "\n",
            "Epoch: 9\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1563/1563 [00:17<00:00, 88.49it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Train set: Average loss: 0.8042, Accuracy: 75.50%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test set: Average loss: 1.8095, Accuracy: 53.76%\n",
            "\n",
            "Epoch: 10\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1563/1563 [00:19<00:00, 78.27it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Train set: Average loss: 0.5739, Accuracy: 78.25%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test set: Average loss: 1.7625, Accuracy: 55.04%\n",
            "Training is end!\n"
          ]
        }
      ],
      "source": [
        "main_CIFAR(model_1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gsMCCTgnqgN-"
      },
      "source": [
        "Видим, что инициализация весов крайне важна для успешного обучения сети. Наглядно увидеть, как от инициализации весов зависит протекание градиентов можно тут https://www.deeplearning.ai/ai-notes/initialization/index.html  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-02-22T18:51:33.357506Z",
          "start_time": "2023-02-22T18:51:33.320991Z"
        },
        "id": "yF67Vc9pibNC"
      },
      "outputs": [],
      "source": [
        "# создаем сверточную сеть для CIFAR10\n",
        "class CIFAR_Net(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        super(CIFAR_Net, self).__init__()\n",
        "\n",
        "        self.conv1 = torch.nn.Conv2d(3, 16, 3, padding=1)\n",
        "        self.act1  = torch.nn.ReLU()\n",
        "        self.pool1 = torch.nn.MaxPool2d(2, 2)\n",
        "\n",
        "        self.conv2 = torch.nn.Conv2d(16, 32, 3, padding=1)\n",
        "        self.act2  = torch.nn.ReLU()\n",
        "        self.pool2 = torch.nn.MaxPool2d(2, 2)\n",
        "\n",
        "        self.conv3 = torch.nn.Conv2d(32, 64, 3, padding=1)\n",
        "        self.act3  = torch.nn.ReLU()\n",
        "\n",
        "        self.fc1   = torch.nn.Linear(8 * 8 * 64, 256)\n",
        "        self.act4  = torch.nn.Tanh()\n",
        "\n",
        "        self.fc2   = torch.nn.Linear(256, 64)\n",
        "        self.act5  = torch.nn.Tanh()\n",
        "\n",
        "        self.fc3   = torch.nn.Linear(64, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv1(x)\n",
        "        x = self.act1(x)\n",
        "        x = self.pool1(x)\n",
        "\n",
        "        x = self.conv2(x)\n",
        "        x = self.act2(x)\n",
        "        x = self.pool2(x)\n",
        "\n",
        "        x = self.conv3(x)\n",
        "        x = self.act3(x)\n",
        "\n",
        "        x = x.view(x.size(0), x.size(1) * x.size(2) * x.size(3))\n",
        "        x = self.fc1(x)\n",
        "        x = self.act4(x)\n",
        "        x = self.fc2(x)\n",
        "        x = self.act5(x)\n",
        "        x = self.fc3(x)\n",
        "\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-02-22T18:51:33.398586Z",
          "start_time": "2023-02-22T18:51:33.374267Z"
        },
        "id": "N6y7CT3Wi2aq"
      },
      "outputs": [],
      "source": [
        "model_CNN = CIFAR_Net()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-02-22T18:51:33.444607Z",
          "start_time": "2023-02-22T18:51:33.402616Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vwcMnT-Ri6lw",
        "outputId": "05d3b1a0-e89a-4a91-cd06-ec94ec1f284c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "====================================================================================================\n",
              "Layer (type:depth-idx)                   Input Shape          Output Shape         Param #\n",
              "====================================================================================================\n",
              "CIFAR_Net                                [32, 3, 32, 32]      [32, 10]             --\n",
              "├─Conv2d: 1-1                            [32, 3, 32, 32]      [32, 16, 32, 32]     448\n",
              "├─ReLU: 1-2                              [32, 16, 32, 32]     [32, 16, 32, 32]     --\n",
              "├─MaxPool2d: 1-3                         [32, 16, 32, 32]     [32, 16, 16, 16]     --\n",
              "├─Conv2d: 1-4                            [32, 16, 16, 16]     [32, 32, 16, 16]     4,640\n",
              "├─ReLU: 1-5                              [32, 32, 16, 16]     [32, 32, 16, 16]     --\n",
              "├─MaxPool2d: 1-6                         [32, 32, 16, 16]     [32, 32, 8, 8]       --\n",
              "├─Conv2d: 1-7                            [32, 32, 8, 8]       [32, 64, 8, 8]       18,496\n",
              "├─ReLU: 1-8                              [32, 64, 8, 8]       [32, 64, 8, 8]       --\n",
              "├─Linear: 1-9                            [32, 4096]           [32, 256]            1,048,832\n",
              "├─Tanh: 1-10                             [32, 256]            [32, 256]            --\n",
              "├─Linear: 1-11                           [32, 256]            [32, 64]             16,448\n",
              "├─Tanh: 1-12                             [32, 64]             [32, 64]             --\n",
              "├─Linear: 1-13                           [32, 64]             [32, 10]             650\n",
              "====================================================================================================\n",
              "Total params: 1,089,514\n",
              "Trainable params: 1,089,514\n",
              "Non-trainable params: 0\n",
              "Total mult-adds (M): 124.68\n",
              "====================================================================================================\n",
              "Input size (MB): 0.39\n",
              "Forward/backward pass size (MB): 7.42\n",
              "Params size (MB): 4.36\n",
              "Estimated Total Size (MB): 12.18\n",
              "===================================================================================================="
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "summary(model=model_CNN,\n",
        "        input_size=(32, 3, 32, 32), # входной батч\n",
        "        col_names=[\"input_size\", \"output_size\", \"num_params\"], # что хотим посмотреть\n",
        "        col_width=20\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "start_time": "2023-02-22T18:37:37.413Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hpJad7NJjGf1",
        "outputId": "a3c999cb-bf25-45e3-9835-bab896f97ee2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ../data/cifar-10-python.tar.gz\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 170498071/170498071 [00:03<00:00, 43686862.75it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracting ../data/cifar-10-python.tar.gz to ../data\n",
            "\n",
            "Epoch: 1\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1563/1563 [00:18<00:00, 84.58it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Train set: Average loss: 1.4697, Accuracy: 48.42%\n",
            "Test set: Average loss: 1.2576, Accuracy: 58.12%\n",
            "\n",
            "Epoch: 2\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1563/1563 [00:20<00:00, 77.84it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Train set: Average loss: 1.1083, Accuracy: 62.52%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test set: Average loss: 1.1313, Accuracy: 64.06%\n",
            "\n",
            "Epoch: 3\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1563/1563 [00:18<00:00, 84.20it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Train set: Average loss: 0.8261, Accuracy: 68.52%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test set: Average loss: 1.0284, Accuracy: 66.98%\n",
            "\n",
            "Epoch: 4\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1563/1563 [00:19<00:00, 79.02it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Train set: Average loss: 0.5281, Accuracy: 72.50%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test set: Average loss: 1.0109, Accuracy: 69.94%\n",
            "\n",
            "Epoch: 5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1563/1563 [00:18<00:00, 83.92it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Train set: Average loss: 0.8086, Accuracy: 76.09%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test set: Average loss: 0.9764, Accuracy: 71.26%\n",
            "\n",
            "Epoch: 6\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1563/1563 [00:19<00:00, 81.77it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Train set: Average loss: 0.3142, Accuracy: 79.35%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test set: Average loss: 0.9737, Accuracy: 71.65%\n",
            "\n",
            "Epoch: 7\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1563/1563 [00:18<00:00, 84.17it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Train set: Average loss: 0.5702, Accuracy: 82.71%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test set: Average loss: 0.9445, Accuracy: 71.87%\n",
            "\n",
            "Epoch: 8\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1563/1563 [00:18<00:00, 84.69it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Train set: Average loss: 0.6263, Accuracy: 85.93%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test set: Average loss: 0.9701, Accuracy: 72.27%\n",
            "\n",
            "Epoch: 9\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1563/1563 [00:19<00:00, 80.72it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Train set: Average loss: 0.3853, Accuracy: 89.41%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test set: Average loss: 0.9634, Accuracy: 72.61%\n",
            "\n",
            "Epoch: 10\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1563/1563 [00:18<00:00, 83.56it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Train set: Average loss: 0.2271, Accuracy: 92.35%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test set: Average loss: 1.0333, Accuracy: 72.51%\n",
            "Training is end!\n"
          ]
        }
      ],
      "source": [
        "main_CIFAR(model_CNN)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NYZkly8gpT0h"
      },
      "source": [
        "Итак, приходится признать очевидный факт: сверточные сети гораздо лучше решают задачу классификации изображений, нежели полносвязанные."
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3.7.5 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.5"
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {},
      "toc_section_display": true,
      "toc_window_display": false
    },
    "vscode": {
      "interpreter": {
        "hash": "c6aeca87e53583627b8b79e4f4da41d10e1acf8a2564923b7f23db1af83b45f2"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
